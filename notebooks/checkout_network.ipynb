{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from time import time_ns\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from rnaquanet.network.graph_regression_network import GraphRegressionNetwork\n",
    "from rnaquanet.network.grn_data_module import GRNDataModule\n",
    "from rnaquanet.utils.rnaquanet_config import RnaquanetConfig\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import h5py\n",
    "from rnaquanet.data.preprocessing.hdf5_utils import load_data_from_hdf5\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstępna konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# konfiguracje można zmienić w locie przy definiowaniu\n",
    "config = RnaquanetConfig('/app/configs/config_ares1.yml', override = {\n",
    "    'network': {\n",
    "        'num_workers': 4\n",
    "    }\n",
    "})\n",
    "config.network.max_epochs = 50\n",
    "\n",
    "data = GRNDataModule(config)\n",
    "data.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperyment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, data, filename):\n",
    "    model = GraphRegressionNetwork(config)\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        filename=filename,\n",
    "        dirpath='/app/models',\n",
    "        save_top_k=1,\n",
    "        mode='min',\n",
    "    )\n",
    "    trainer = pl.Trainer(max_epochs=config.network.max_epochs, log_every_n_steps=1, callbacks=[\n",
    "        EarlyStopping('val_loss', patience=4),\n",
    "        checkpoint\n",
    "    ]) \n",
    "    trainer.fit(model, data)\n",
    "    return GraphRegressionNetwork.load_from_checkpoint(checkpoint.best_model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "def get_scores(config, model):\n",
    "    scores = {\n",
    "        # @structure_name: {\n",
    "        #   @loss: []\n",
    "        #   @dataset: 'train'|'val'|'test'\n",
    "        #   @nucleotides: number\n",
    "        # }\n",
    "    }\n",
    "    for dataset in ['train', 'val', 'test']:\n",
    "        file_path = os.path.join(config.data.path, config.name, f'{dataset}.h5')\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            for key, value in file.items(): # key is structure name\n",
    "                if isinstance(value, h5py.Group):\n",
    "                    key = key[0:4]\n",
    "                    if not key in scores:\n",
    "                        scores[key] = {\n",
    "                            'loss': [],\n",
    "                            'dataset': dataset,\n",
    "                            'nucleotides': torch.tensor(value['x'][()]).shape[0]\n",
    "                        }\n",
    "\n",
    "                    model.eval()\n",
    "                    for sample in DataLoader([Data(\n",
    "                        x=torch.tensor(value['x'][()]),\n",
    "                        edge_index=torch.tensor(value['edge_index'][()]),\n",
    "                        edge_attr=torch.tensor(value['edge_attr'][()]),\n",
    "                        y=torch.tensor(value['y'][()]) if value.get('y') is not None else None\n",
    "                    )], batch_size=1):\n",
    "                        scores[key]['loss'].append(F.mse_loss(model(\n",
    "                            sample.x.to(device), \n",
    "                            sample.edge_index.to(device), \n",
    "                            sample.edge_attr.to(device), \n",
    "                            sample.batch.to(device)\n",
    "                        ).cpu(), sample.y.cpu().view(-1, 1)).item())\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, title = 'Mean loss'):\n",
    "    colors = {\n",
    "        'train': 'pink',\n",
    "        'val': 'lightblue',\n",
    "        'test': 'lightgreen'\n",
    "    }\n",
    "    plt.bar(\n",
    "        x=list(map(lambda key: f'{key} ({scores[key][\"nucleotides\"]})',scores.keys())), \n",
    "        height=list(map(lambda score: np.mean(score['loss']), scores.values())), \n",
    "        color=list(map(lambda score: colors[score['dataset']], scores.values()))\n",
    "    )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=90)\n",
    "    legend_labels = {v: k for k, v in colors.items()}\n",
    "    legend_handles = [plt.Rectangle((0, 0), 1, 1, color=c) for c in colors.values()]\n",
    "    plt.legend(legend_handles, legend_labels.values())\n",
    "\n",
    "    plt.xlabel('Structure')\n",
    "    plt.ylabel('Mean loss')\n",
    "    plt.savefig(title.lower().replace(' ', '_') + '.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    'batch_size': {\n",
    "        10: [],\n",
    "        100: [],\n",
    "        1000: []\n",
    "    },\n",
    "    'hidden_dim': {\n",
    "        64: [],\n",
    "        128: [],\n",
    "        256: []\n",
    "    },\n",
    "    'layer_type': {\n",
    "        1: [],\n",
    "        3: []\n",
    "    },\n",
    "    'batch_norm': {\n",
    "        True: [],\n",
    "        False: []\n",
    "    },\n",
    "    'num_of_layers': {\n",
    "        4: [],\n",
    "        16: []\n",
    "    }\n",
    "}\n",
    "\n",
    "for batch_size in [10, 100, 1000]:\n",
    "    for hidden_dim in [64, 128, 256]:\n",
    "        for layer_type in [1, 3]:\n",
    "            for batch_norm in [True, False]:\n",
    "                for num_of_layers in [4, 16]:\n",
    "                    data.batch_size = batch_size\n",
    "                    config.hidden_dim = hidden_dim\n",
    "                    config.layer_type = layer_type\n",
    "                    config.batch_norm = batch_norm\n",
    "                    config.num_of_layers = num_of_layers\n",
    "                    torch.manual_seed(2137)\n",
    "                    try:\n",
    "                        model = train_model(config, data, f'{batch_size}_{hidden_dim}_{layer_type}_{batch_norm}_{num_of_layers}')\n",
    "                        scores = get_scores(config, model)\n",
    "                        plot_scores(scores, title=f'{batch_size}, {hidden_dim}, {layer_type}, {batch_norm}, {num_of_layers}')\n",
    "                        val_mean = np.mean(np.concatenate([score['loss'] for score in scores.values() if score['dataset'] == 'val']))\n",
    "                        output['batch_size'][batch_size].append(val_mean)\n",
    "                        output['hidden_dim'][hidden_dim].append(val_mean)\n",
    "                        output['layer_type'][layer_type].append(val_mean)\n",
    "                        output['batch_norm'][batch_norm].append(val_mean)\n",
    "                        output['num_of_layers'][num_of_layers].append(val_mean)\n",
    "                    except:\n",
    "                        print(f'Failed at {batch_size}, {hidden_dim}, {layer_type}, {batch_norm}, {num_of_layers}')\n",
    "\n",
    "for key, value in output.items():\n",
    "    plt.bar(\n",
    "        x=list(map(lambda x: str(x), value.keys())),\n",
    "        height=list(map(lambda val: np.mean(val), value.values()))\n",
    "    )\n",
    "\n",
    "    plt.title(f'Mean val loss {key}')\n",
    "    plt.xlabel(key)\n",
    "    plt.ylabel('Mean loss')\n",
    "    plt.savefig('val_' + key + '.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
