{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from time import time_ns\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from rnaquanet.network.graph_regression_network import GraphRegressionNetwork\n",
    "from rnaquanet.network.grn_data_module import GRNDataModule\n",
    "from rnaquanet.utils.rnaquanet_config import RnaquanetConfig\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import Adam\n",
    "from torch.nn import (\n",
    "    BatchNorm1d,\n",
    "    Identity,\n",
    "    ReLU,\n",
    "    LeakyReLU,\n",
    "    Linear,\n",
    "    MSELoss\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import (\n",
    "    GATConv,\n",
    "    GCNConv,\n",
    "    Sequential,\n",
    "    global_mean_pool,\n",
    "    BatchNorm,\n",
    "    TransformerConv\n",
    ")\n",
    "from torch_geometric.nn.models import (\n",
    "    GAT\n",
    ")\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from rnaquanet.data.preprocessing.hdf5_utils import load_data_from_hdf5\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from rnaquanet.network.h5_graph_dataset import H5GraphDataset\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg1_train_data = H5GraphDataset('/app/data/segments_1_coords/train.h5').__enter__()\n",
    "\n",
    "seg1_val_data = H5GraphDataset('/app/data/segments_1_coords/val.h5').__enter__()\n",
    "seg1_test_data = H5GraphDataset('/app/data/segments_1_coords/test.h5').__enter__()\n",
    "\n",
    "seg2_val_data = H5GraphDataset('/app/data/segments_2_coords/val.h5').__enter__()\n",
    "seg2_test_data = H5GraphDataset('/app/data/segments_2_coords/test.h5').__enter__()\n",
    "\n",
    "seg3_val_data = H5GraphDataset('/app/data/segments_3_coords/val.h5').__enter__()\n",
    "seg3_test_data = H5GraphDataset('/app/data/segments_3_coords/test.h5').__enter__()\n",
    "\n",
    "ares_val_data = H5GraphDataset('/app/data/ares/val.h5').__enter__()\n",
    "ares_test_data = H5GraphDataset('/app/data/ares/test.h5').__enter__()\n",
    "\n",
    "dataset = 'seg1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_chart(losses, epoch):\n",
    "    bars = len(losses.values()) # num of bars\n",
    "    epochs = range(1, epoch+2)\n",
    "    width = 1.0/bars * 0.75\n",
    "    multiplier = 0\n",
    "    _, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "    for key, value in losses.items():\n",
    "        x = np.arange(len(value['losses']))\n",
    "\n",
    "        loss_values = value['losses']\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, loss_values, width, label=key, color=value['color'], alpha=0.5)\n",
    "        ax.bar_label(rects, fmt='%0.0f', padding=3)\n",
    "        ax.plot(x+((bars-1)/2)*width, loss_values, color=value['color'], alpha=0.5)\n",
    "        multiplier += 1\n",
    "\n",
    "    x = np.arange(len(epochs))\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_xticks(x + ((bars-1)/2)*width, epochs)\n",
    "    ax.legend()\n",
    "    plt.savefig(os.path.join('train', f'{dataset}.png'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_desc(epoch, losses):\n",
    "    desc = f'Epoch {epoch+1}\\n'\n",
    "    for key, value in losses.items():\n",
    "        if value['losses']:\n",
    "            desc += f'Prev {key} {value[\"losses\"][-1]:.2f}\\tBest {key} {np.min(value[\"losses\"]):.2f}\\n'\n",
    "    return desc.rstrip('\\n')\n",
    "\n",
    "def process_epoch(\n",
    "        epoch, \n",
    "        batch_size, \n",
    "        device, \n",
    "        model,\n",
    "        loss_fn,\n",
    "        mse_no_reduce,\n",
    "        optimizer,\n",
    "        patience, \n",
    "        \n",
    "        losses, key,\n",
    "        best_model, best_loss,\n",
    "\n",
    "        save_values = False,\n",
    "        plot = True\n",
    "    ):\n",
    "    step = []\n",
    "    values = {'predicted': [], 'true': []}\n",
    "    assert(not losses[key]['train'] or not save_values)\n",
    "\n",
    "    if losses[key]['data'].max_iterations != None:\n",
    "        losses[key]['data'].shuffle()\n",
    "    \n",
    "\n",
    "    with tqdm(total=len(losses[key]['data']), desc=f'{key.capitalize()} epoch {epoch+1}', position=0, leave=True) as progressbar:\n",
    "        if not losses[key]['train']:\n",
    "            with torch.no_grad():\n",
    "                for item in DataLoader(losses[key]['data'], batch_size=batch_size, shuffle=False, num_workers=4):\n",
    "                    item = item.to(device)\n",
    "                    y_pred = model(x=item.x, edge_index=item.edge_index, edge_attr=item.edge_attr, batch=item.batch).view(-1)\n",
    "                    step.extend(mse_no_reduce(y_pred, item.y).cpu().tolist())\n",
    "                    if save_values:\n",
    "                        values['predicted'].extend(y_pred.cpu().tolist())\n",
    "                        values['true'].extend(item.y.view(-1).cpu().tolist())\n",
    "                    progressbar.update(item.y.cpu().shape[0])\n",
    "        else:\n",
    "            for item in DataLoader(losses[key]['data'], batch_size=batch_size, shuffle=(losses[key]['data'].max_iterations == None), num_workers=4):\n",
    "                item = item.to(device)\n",
    "                y_pred = model(x=item.x, edge_index=item.edge_index, edge_attr=item.edge_attr, batch=item.batch).view(-1)\n",
    "                loss = loss_fn(y_pred, item.y)\n",
    "                step.extend(mse_no_reduce(y_pred, item.y).cpu().tolist())\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                progressbar.update(item.y.cpu().shape[0])\n",
    "        \n",
    "    losses[key]['losses'].append(np.mean(step))\n",
    "    if save_values:\n",
    "        losses[key]['values'].append(values)\n",
    "    clear_output(wait=True)\n",
    "    print(get_desc(epoch, losses))\n",
    "    if plot:\n",
    "        plot_loss_chart(losses, epoch)\n",
    "\n",
    "    index = np.argmin(losses[key]['losses'])\n",
    "    if losses[key]['patience']:\n",
    "        if losses[key]['losses'][-1] < best_loss:\n",
    "            return model.state_dict().copy(), losses[key]['losses'][index], False\n",
    "    return best_model, best_loss, losses[key]['patience'] and index <= (epoch-patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "torch.manual_seed(2137)\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "max_epochs = 1000\n",
    "batch_size = 32\n",
    "patience = 3\n",
    "\n",
    "model = Sequential('x, edge_index, edge_attr, batch', [\n",
    "    (GATConv(in_channels=99, out_channels=256, heads=4, dropout=0.5), 'x, edge_index, edge_attr -> x'),\n",
    "    (BatchNorm(in_channels=256*4), 'x -> x'),\n",
    "    (ReLU(), 'x -> x'),\n",
    "    (GATConv(in_channels=256*4, out_channels=256, heads=8, dropout=0.5), 'x, edge_index, edge_attr -> x'),\n",
    "    (BatchNorm(in_channels=256*8), 'x -> x'),\n",
    "    (ReLU(), 'x -> x'),\n",
    "\n",
    "    (GCNConv(in_channels=256*8, out_channels=256), 'x, edge_index -> x'),\n",
    "    (global_mean_pool, 'x, batch -> x'),\n",
    "\n",
    "    (Linear(in_features=256, out_features=64), 'x -> x'),\n",
    "    (ReLU(), 'x -> x'),\n",
    "    (Linear(in_features=64, out_features=1), 'x -> x'),\n",
    "]).to(device)\n",
    "\n",
    "loss_fn = MSELoss(reduction='mean').to(device)\n",
    "mse_no_reduce = MSELoss(reduction='none').to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "losses = {\n",
    "    'seg1 train': {\n",
    "        'data': seg1_train_data,\n",
    "        'losses': [],\n",
    "        'color': 'red',\n",
    "        'train': True,\n",
    "        'patience': False\n",
    "    },\n",
    "    'seg1 val': {\n",
    "        'data': seg1_val_data,\n",
    "        'losses': [],\n",
    "        'color': 'blue',\n",
    "        'train': False,\n",
    "        'patience': True,\n",
    "        'values': []\n",
    "    },\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for key in losses.keys():\n",
    "        best_model, best_loss, cond = process_epoch(epoch, batch_size, device, model, loss_fn, mse_no_reduce, optimizer, patience, losses, key, best_model, best_loss)\n",
    "        if cond:\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "\n",
    "torch.save(best_model, os.path.join('model', f'{dataset}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted\tground truth\tdiff\n",
      "6.58615779876709\t0.8009999990463257\t5.785157799720764\n",
      "5.505395889282227\t2.2249999046325684\t3.280395984649658\n",
      "5.700244903564453\t1.9639999866485596\t3.7362449169158936\n",
      "5.0140886306762695\t2.302999973297119\t2.7110886573791504\n",
      "8.450472831726074\t2.2809998989105225\t6.169472932815552\n",
      "5.362732410430908\t4.642000198364258\t0.7207322120666504\n",
      "5.826169967651367\t9.298999786376953\t-3.472829818725586\n",
      "6.755646705627441\t1.781999945640564\t4.973646759986877\n",
      "3.981149911880493\t6.171999931335449\t-2.190850019454956\n",
      "4.908929347991943\t4.124000072479248\t0.7849292755126953\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    n = 0\n",
    "    print(f'predicted\\tground truth\\tdiff')\n",
    "    for item in DataLoader(losses['seg1 val']['data'], batch_size=1, shuffle=True, num_workers=4):\n",
    "        item = item.to(device)\n",
    "        y_pred = model(x=item.x, edge_index=item.edge_index, edge_attr=item.edge_attr, batch=item.batch).view(-1)\n",
    "        print(f'{y_pred.cpu().item()}\\t{item.y.cpu().item()}\\t{y_pred.cpu().item()-item.y.cpu().item()}')\n",
    "        n += 1\n",
    "        if n == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Prev ares val 11.87\tBest ares val 11.87\n",
      "Prev ares test 17.06\tBest ares test 17.06\n",
      "Prev seg1 val 12.70\tBest seg1 val 12.70\n",
      "Prev seg1 test 12.44\tBest seg1 test 12.44\n",
      "Prev seg2 val 33.95\tBest seg2 val 33.95\n",
      "Prev seg2 test 33.86\tBest seg2 test 33.86\n",
      "Prev seg3 val 67.82\tBest seg3 val 67.82\n",
      "Prev seg3 test 74.12\tBest seg3 test 74.12\n"
     ]
    }
   ],
   "source": [
    "losses = {\n",
    "    'ares val': {\n",
    "        'data': ares_val_data,\n",
    "        'losses': [],\n",
    "        'color': '',\n",
    "        'train': False,\n",
    "        'patience': False,\n",
    "        'values': []\n",
    "    },\n",
    "    'ares test': {\n",
    "        'data': ares_test_data,\n",
    "        'losses': [],\n",
    "        'color': '',\n",
    "        'train': False,\n",
    "        'patience': False,\n",
    "        'values': []\n",
    "    },\n",
    "    'seg1 val': {\n",
    "        'data': seg1_val_data,\n",
    "        'losses': [],\n",
    "        'color': '',\n",
    "        'train': False,\n",
    "        'patience': False,\n",
    "        'values': []\n",
    "    },\n",
    "    'seg1 test': {\n",
    "        'data': seg1_test_data,\n",
    "        'losses': [],\n",
    "        'color': '',\n",
    "        'train': False,\n",
    "        'patience': False,\n",
    "        'values': []\n",
    "    },\n",
    "    'seg2 val': {\n",
    "        'data': seg2_val_data,\n",
    "        'losses': [],\n",
    "        'color': '',\n",
    "        'train': False,\n",
    "        'patience': False,\n",
    "        'values': []\n",
    "    },\n",
    "    'seg2 test': {\n",
    "        'data': seg2_test_data,\n",
    "        'losses': [],\n",
    "        'color': '',\n",
    "        'train': False,\n",
    "        'patience': False,\n",
    "        'values': []\n",
    "    },\n",
    "    'seg3 val': {\n",
    "        'data': seg3_val_data,\n",
    "        'losses': [],\n",
    "        'color': '',\n",
    "        'train': False,\n",
    "        'patience': False,\n",
    "        'values': []\n",
    "    },\n",
    "    'seg3 test': {\n",
    "        'data': seg3_test_data,\n",
    "        'losses': [],\n",
    "        'color': '',\n",
    "        'train': False,\n",
    "        'patience': False,\n",
    "        'values': []\n",
    "    },\n",
    "}\n",
    "\n",
    "for key in losses.keys():\n",
    "    process_epoch(0, batch_size, device, model, loss_fn, mse_no_reduce, optimizer, patience, losses, key, best_model, best_loss, save_values=True, plot=False)\n",
    "    values = losses[key]['values'].pop()\n",
    "    plt.boxplot([values['predicted'], values['true']], labels=['Predicted', 'Ground Truth'])\n",
    "    plt.title(f'{key.capitalize()} Values Box Plot (Trained on Seg1)')\n",
    "    plt.ylabel('Values')\n",
    "    plt.savefig(os.path.join('values', f'{dataset}_{key.replace(\" \", \"_\")}.png'))\n",
    "    plt.close()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(list(losses.keys()), list(map(lambda l: l['losses'][0], losses.values())))\n",
    "plt.title(f'Average Loss Across Datasets (Trained on Seg1)')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig(os.path.join('loss', f'{dataset}.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "rects = plt.bar(list(losses.keys()), list(map(lambda l: l['losses'][0], losses.values())))\n",
    "plt.bar_label(rects, fmt='%0.0f', padding=3)\n",
    "plt.title(f'Average Loss Across Datasets (Trained on Seg1)')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig(os.path.join('loss', f'{dataset}.png'))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
